{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O gradient boosting and grid search\n",
    "\n",
    "In this tutorial I will show you how to build and tune an H2O gbm model. I will first build a baseline gbm model without tuning the hyperparameters. Then I fine-tune the gbm model with hyperparameters in the gbm function. Then I use h2o.grid to conduct an extensive grid search to optimize the performance. You will see the model performance, measured by the area under the curve (AUC) in our case, has improved dramatically.\n",
    "\n",
    "We will use the dataset [Gender recognition by voice](https://www.kaggle.com/primaryobjects/voicegender) on the Kaggle site.\n",
    "\n",
    "The H2Oâ€™s GBM supports the following functionalities:\n",
    "* Supervised learning for regression and classification tasks\n",
    "* Distributed and parallelized computation on either a single node or a multi-node cluster\n",
    "* Fast and memory-efficient Java implementations of the underlying algorithms\n",
    "* User-friendly web interface to mirror the model building and scoring process running in R or Python\n",
    "* Grid search for hyperparameter optimization and model selection\n",
    "* Model export in plain Java code for deployment in production environments\n",
    "* Additional parameters for model tuning.\n",
    "\n",
    "\n",
    "We use h2o.init(nthreads=-1) to initilize an h2o environment. \"Number of threads\" is pretty much the number of CPUs used for a laptop. -1 means use all CPUs on the host (Default). A positive integer specifies the number of CPUs directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "H2O is not running yet, starting it now...\n",
      "\n",
      "Note:  In case of errors look at the following log files:\n",
      "    /var/folders/jw/wyhtzlf94zbgtpf9g_n5tryr0000gn/T//RtmpWgZL04/h2o_chriskuo_started_from_r.out\n",
      "    /var/folders/jw/wyhtzlf94zbgtpf9g_n5tryr0000gn/T//RtmpWgZL04/h2o_chriskuo_started_from_r.err\n",
      "\n",
      "\n",
      "Starting H2O JVM and connecting: .. Connection successful!\n",
      "\n",
      "R is connected to the H2O cluster: \n",
      "    H2O cluster uptime:         2 seconds 81 milliseconds \n",
      "    H2O cluster timezone:       America/New_York \n",
      "    H2O data parsing timezone:  UTC \n",
      "    H2O cluster version:        3.21.0.4353 \n",
      "    H2O cluster version age:    8 days  \n",
      "    H2O cluster name:           H2O_started_from_R_chriskuo_hpm901 \n",
      "    H2O cluster total nodes:    1 \n",
      "    H2O cluster total memory:   1.78 GB \n",
      "    H2O cluster total cores:    4 \n",
      "    H2O cluster allowed cores:  4 \n",
      "    H2O cluster healthy:        TRUE \n",
      "    H2O Connection ip:          localhost \n",
      "    H2O Connection port:        54321 \n",
      "    H2O Connection proxy:       NA \n",
      "    H2O Internal Security:      FALSE \n",
      "    H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 \n",
      "    R Version:                  R version 3.4.3 (2017-11-30) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(h2o)\n",
    "h2o.init(nthreads=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>3168</li>\n",
       "\t<li>21</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3168\n",
       "\\item 21\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3168\n",
       "2. 21\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 3168   21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       " meanfreq          sd                median            Q25                \n",
       " Min.   :0.03936   Min.   :0.01836   Min.   :0.01097   Min.   :0.0002288  \n",
       " 1st Qu.:0.16366   1st Qu.:0.04195   1st Qu.:0.16959   1st Qu.:0.1110865  \n",
       " Median :0.18484   Median :0.05916   Median :0.19003   Median :0.1402864  \n",
       " Mean   :0.18091   Mean   :0.05713   Mean   :0.18562   Mean   :0.1404556  \n",
       " 3rd Qu.:0.19915   3rd Qu.:0.06702   3rd Qu.:0.21062   3rd Qu.:0.1759388  \n",
       " Max.   :0.25112   Max.   :0.11527   Max.   :0.26122   Max.   :0.2473469  \n",
       " Q75               IQR               skew              kurt              \n",
       " Min.   :0.04295   Min.   :0.01456   Min.   : 0.1417   Min.   :   2.068  \n",
       " 1st Qu.:0.20875   1st Qu.:0.04256   1st Qu.: 1.6496   1st Qu.:   5.670  \n",
       " Median :0.22568   Median :0.09428   Median : 2.1971   Median :   8.318  \n",
       " Mean   :0.22476   Mean   :0.08431   Mean   : 3.1402   Mean   :  36.568  \n",
       " 3rd Qu.:0.24366   3rd Qu.:0.11418   3rd Qu.: 2.9317   3rd Qu.:  13.649  \n",
       " Max.   :0.27347   Max.   :0.25223   Max.   :34.7255   Max.   :1309.613  \n",
       " sp.ent           sfm               mode             centroid         \n",
       " Min.   :0.7387   Min.   :0.03688   Min.   :0.0000   Min.   :0.03936  \n",
       " 1st Qu.:0.8618   1st Qu.:0.25804   1st Qu.:0.1180   1st Qu.:0.16366  \n",
       " Median :0.9018   Median :0.39634   Median :0.1866   Median :0.18484  \n",
       " Mean   :0.8951   Mean   :0.40822   Mean   :0.1653   Mean   :0.18091  \n",
       " 3rd Qu.:0.9287   3rd Qu.:0.53368   3rd Qu.:0.2211   3rd Qu.:0.19915  \n",
       " Max.   :0.9820   Max.   :0.84294   Max.   :0.2800   Max.   :0.25112  \n",
       " meanfun           minfun             maxfun           meandom           \n",
       " Min.   :0.05557   Min.   :0.009775   Min.   :0.1031   Min.   :0.007812  \n",
       " 1st Qu.:0.11700   1st Qu.:0.018223   1st Qu.:0.2540   1st Qu.:0.419828  \n",
       " Median :0.14052   Median :0.046110   Median :0.2712   Median :0.765795  \n",
       " Mean   :0.14281   Mean   :0.036802   Mean   :0.2588   Mean   :0.829211  \n",
       " 3rd Qu.:0.16958   3rd Qu.:0.047904   3rd Qu.:0.2775   3rd Qu.:1.177166  \n",
       " Max.   :0.23764   Max.   :0.204082   Max.   :0.2791   Max.   :2.957682  \n",
       " mindom             maxdom              dfrange          modindx          \n",
       " Min.   :0.004883   Min.   : 0.007812   Min.   : 0.000   Min.   :0.00000  \n",
       " 1st Qu.:0.007812   1st Qu.: 2.070312   1st Qu.: 2.045   1st Qu.:0.09977  \n",
       " Median :0.023438   Median : 4.992188   Median : 4.945   Median :0.13936  \n",
       " Mean   :0.052647   Mean   : 5.047277   Mean   : 4.995   Mean   :0.17375  \n",
       " 3rd Qu.:0.070312   3rd Qu.: 7.007812   3rd Qu.: 6.992   3rd Qu.:0.20918  \n",
       " Max.   :0.458984   Max.   :21.867188   Max.   :21.844   Max.   :0.93237  \n",
       " label       \n",
       " female:1584 \n",
       " male  :1584 \n",
       "             \n",
       "             \n",
       "             \n",
       "             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'meanfreq'</li>\n",
       "\t<li>'sd'</li>\n",
       "\t<li>'median'</li>\n",
       "\t<li>'Q25'</li>\n",
       "\t<li>'Q75'</li>\n",
       "\t<li>'IQR'</li>\n",
       "\t<li>'skew'</li>\n",
       "\t<li>'kurt'</li>\n",
       "\t<li>'sp.ent'</li>\n",
       "\t<li>'sfm'</li>\n",
       "\t<li>'mode'</li>\n",
       "\t<li>'centroid'</li>\n",
       "\t<li>'meanfun'</li>\n",
       "\t<li>'minfun'</li>\n",
       "\t<li>'maxfun'</li>\n",
       "\t<li>'meandom'</li>\n",
       "\t<li>'mindom'</li>\n",
       "\t<li>'maxdom'</li>\n",
       "\t<li>'dfrange'</li>\n",
       "\t<li>'modindx'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'meanfreq'\n",
       "\\item 'sd'\n",
       "\\item 'median'\n",
       "\\item 'Q25'\n",
       "\\item 'Q75'\n",
       "\\item 'IQR'\n",
       "\\item 'skew'\n",
       "\\item 'kurt'\n",
       "\\item 'sp.ent'\n",
       "\\item 'sfm'\n",
       "\\item 'mode'\n",
       "\\item 'centroid'\n",
       "\\item 'meanfun'\n",
       "\\item 'minfun'\n",
       "\\item 'maxfun'\n",
       "\\item 'meandom'\n",
       "\\item 'mindom'\n",
       "\\item 'maxdom'\n",
       "\\item 'dfrange'\n",
       "\\item 'modindx'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'meanfreq'\n",
       "2. 'sd'\n",
       "3. 'median'\n",
       "4. 'Q25'\n",
       "5. 'Q75'\n",
       "6. 'IQR'\n",
       "7. 'skew'\n",
       "8. 'kurt'\n",
       "9. 'sp.ent'\n",
       "10. 'sfm'\n",
       "11. 'mode'\n",
       "12. 'centroid'\n",
       "13. 'meanfun'\n",
       "14. 'minfun'\n",
       "15. 'maxfun'\n",
       "16. 'meandom'\n",
       "17. 'mindom'\n",
       "18. 'maxdom'\n",
       "19. 'dfrange'\n",
       "20. 'modindx'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"meanfreq\" \"sd\"       \"median\"   \"Q25\"      \"Q75\"      \"IQR\"     \n",
       " [7] \"skew\"     \"kurt\"     \"sp.ent\"   \"sfm\"      \"mode\"     \"centroid\"\n",
       "[13] \"meanfun\"  \"minfun\"   \"maxfun\"   \"meandom\"  \"mindom\"   \"maxdom\"  \n",
       "[19] \"dfrange\"  \"modindx\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df <- h2o.importFile(path = \"/Users/chriskuo/Downloads/voice.csv\")\n",
    "dim(df)\n",
    "summary(df,exact_quantiles=TRUE)\n",
    "\n",
    "# Specify the response variable\n",
    "response <- \"label\"\n",
    "\n",
    "# Make the response variable a categorical variable\n",
    "df[[response]] <- as.factor(df[[response]])      \n",
    "\n",
    "## Exclude the variable 'Type'\n",
    "predictors <- setdiff(names(df), 'label')\n",
    "predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "Below is the standard syntax of h2o to split the dataset for training and testing purpose. In order to run and test on small samples, I use 10% for training and 10% for validation. H2o requires only two ratios. The third one is implied. So the test dataset is 90% (but I will not use it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits <- h2o.splitFrame(\n",
    "  data = df, \n",
    "  ratios = c(0.1,0.1),   # the ratios should sum up to to be less than 1.0. \n",
    "    destination_frames = c(\"train\", \"valid\", \"test\"), seed = 1234\n",
    ")\n",
    "train <- splits[[1]]\n",
    "valid <- splits[[2]]\n",
    "test  <- splits[[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objective 1: Build a baseline gbm model without hyper-parameter tuning\n",
    "\n",
    "Below I just use all the default values for the hyperpamaters. The AUC on the validation data is 0.569. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model Details:\n",
       "==============\n",
       "\n",
       "H2OBinomialModel: gbm\n",
       "Model ID:  GBM_model_R_1532025355299_41 \n",
       "Model Summary: \n",
       "  number_of_trees number_of_internal_trees model_size_in_bytes min_depth\n",
       "1              50                       50               11060         4\n",
       "  max_depth mean_depth min_leaves max_leaves mean_leaves\n",
       "1         5    4.98000          6         15    12.72000\n",
       "\n",
       "\n",
       "H2OBinomialMetrics: gbm\n",
       "** Reported on training data. **\n",
       "\n",
       "MSE:  0.000328585\n",
       "RMSE:  0.01812691\n",
       "LogLoss:  0.008934396\n",
       "Mean Per-Class Error:  0\n",
       "AUC:  1\n",
       "Gini:  1\n",
       "\n",
       "Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n",
       "       female male    Error    Rate\n",
       "female    150    0 0.000000  =0/150\n",
       "male        0  161 0.000000  =0/161\n",
       "Totals    150  161 0.000000  =0/311\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "                        metric threshold    value idx\n",
       "1                       max f1  0.815335 1.000000  94\n",
       "2                       max f2  0.815335 1.000000  94\n",
       "3                 max f0point5  0.815335 1.000000  94\n",
       "4                 max accuracy  0.815335 1.000000  94\n",
       "5                max precision  0.997230 1.000000   0\n",
       "6                   max recall  0.815335 1.000000  94\n",
       "7              max specificity  0.997230 1.000000   0\n",
       "8             max absolute_mcc  0.815335 1.000000  94\n",
       "9   max min_per_class_accuracy  0.815335 1.000000  94\n",
       "10 max mean_per_class_accuracy  0.815335 1.000000  94\n",
       "\n",
       "Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.99140625"
      ],
      "text/latex": [
       "0.99140625"
      ],
      "text/markdown": [
       "0.99140625"
      ],
      "text/plain": [
       "[1] 0.9914063"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm <- h2o.gbm(x = predictors, y = response, training_frame = train)\n",
    "gbm\n",
    "\n",
    "## Get the AUC on the validation set\n",
    "h2o.auc(h2o.performance(gbm, newdata = valid)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find-tune hyper-parameters in h2o.gbm\n",
    "\n",
    "The overall strategy is to test more trees and smaller learning rate. The hyperparameters for tuning are the following:\n",
    "\n",
    "* Learning rate (shrinkage)\n",
    "* Number of trees\n",
    "* Interaction depth\n",
    "* Minimum observation in a node\n",
    "* Bag fraction (fraction of randomly selected observations)\n",
    "\n",
    "\n",
    "The learning rate, a value between 0 and 1, corresponds to how quickly the error is corrected from each tree to the next. A small learning rate will result in long computational time, and a large learning rate makes the system unable to settle down. It will be efficient if the learning rate can decay over time. Therefore there is a hyperparameter to decay the learning rate called the \"learn_rate_annealing\". \"Annealing\", in materials science, describes a heating process that heats up in the beginning then cools down slowly. In gbm a common way to decay the learning rate is call the \"step decay\". It reduces the learning rate by some factor in every few iterations or epochs. Typical values are to reduce the learning rate by a half every 5 epochs. Because we use learning_rate_annealing, we can start with a large learning rate=0.05.\n",
    "\n",
    "* learn_rate= 0.05.\n",
    "* learn_rate_annealing=0.99.\n",
    "* ntrees = 1000.\n",
    "* max_runtime_secs=1200. Early stopping based on timeout. In this case no more than 1200 seconds.\n",
    "* stopping_rounds = 5.\n",
    "* stopping_tolerance = 1e-4.\n",
    "* stopping_metric = \"AUC\". The above three hyperparameters control the early stopping when the AUC does not improve by at least 0.01% for 5 consecutive scoring events.\n",
    "* score_tree_interval = 10. Score every 10 trees to make early stopping reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n",
      "[1] 0.9892323\n"
     ]
    }
   ],
   "source": [
    "gbm <- h2o.gbm(x = predictors, y = response, \n",
    "               training_frame = train, \n",
    "               validation_frame = valid,\n",
    "               learn_rate = .05, learn_rate_annealing =.99,\n",
    "               ntrees=1000,\n",
    "               stopping_rounds = 5,\n",
    "               stopping_tolerance = 1e-4,\n",
    "               stopping_metric = \"AUC\", \n",
    "               seed = 1234)\n",
    "\n",
    "# print the auc for the validation data\n",
    "print(h2o.auc(gbm, valid = TRUE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objective 2: Use Grid-search to find the optimal hyper-parameters\n",
    "\n",
    "You can type \"?h2o.grid()\" to understand the grid serach options. The h2o.grid() reserves the following commands:\n",
    "\n",
    "* hyper_params: List of lists of hyper parameters. \n",
    "* search_criteria: The default strategy 'Cartesian' covers the entire space of hyperparameter combinations. For example, if you have three hyperparameters and you have 2, 4, 6 values for each, the Catesian search will result in $2 * 4 * 6 = 48$ models. The alternative is 'RandomDiscrete' strategy to get random search of all the combinations of your hyperparameters. \n",
    "* algorithm: Which algorithm.\n",
    "* grid_id: An id that we can retrieve it later. In this example is \"my_grid\".\n",
    "* ntrees: The number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "H2O Grid Details\n",
       "================\n",
       "\n",
       "Grid ID: my_grid \n",
       "Used hyper parameters: \n",
       "  -  max_depth \n",
       "  -  ntrees \n",
       "Number of models: 60 \n",
       "Number of failed models: 0 \n",
       "\n",
       "Hyper-Parameter Search Summary: ordered by increasing logloss\n",
       "  max_depth ntrees        model_ids             logloss\n",
       "1         8   1100 my_grid_model_22 0.10107007986622381\n",
       "2         8   2700 my_grid_model_54 0.10107007986622381\n",
       "3         8   1900 my_grid_model_38 0.10107007986622381\n",
       "4         8    700 my_grid_model_14 0.10107007986622381\n",
       "5         8    100  my_grid_model_2 0.10107007986622381\n",
       "\n",
       "---\n",
       "   max_depth ntrees        model_ids             logloss\n",
       "55         2    300  my_grid_model_4 0.11186495832129566\n",
       "56         2   1300 my_grid_model_24 0.11186495832129566\n",
       "57         2    700 my_grid_model_12 0.11186495832129566\n",
       "58         2   2500 my_grid_model_48 0.11186495832129566\n",
       "59         2    900 my_grid_model_16 0.11186495832129566\n",
       "60         2    100  my_grid_model_0 0.11463976462939442"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyper_params = list( ntrees = seq(100,3000,200), \n",
    "                    max_depth=seq(2,12,3)   )\n",
    "\n",
    "grid <- h2o.grid(\n",
    "  hyper_params = hyper_params,\n",
    "  \n",
    "  search_criteria = list(strategy = \"Cartesian\"),\n",
    "  \n",
    "  algorithm=\"gbm\",\n",
    "  \n",
    "  grid_id=\"my_grid\",\n",
    "  \n",
    "  # Below are is the same as h2o.gbm()\n",
    "  x = predictors, \n",
    "  y = response, \n",
    "  training_frame = train, \n",
    "  validation_frame = valid,\n",
    "  learn_rate = 0.05,                                                         \n",
    "  learn_rate_annealing = 0.99,                                               \n",
    "  sample_rate = 0.8,                                                       \n",
    "  col_sample_rate = 0.8, \n",
    "  seed = 1234,                                                             \n",
    "  stopping_rounds = 5,\n",
    "  stopping_tolerance = 1e-4,\n",
    "  stopping_metric = \"AUC\", \n",
    "  score_tree_interval = 10                                                \n",
    ")\n",
    "\n",
    "grid        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O Grid Details\n",
      "================\n",
      "\n",
      "Grid ID: my_grid \n",
      "Used hyper parameters: \n",
      "  -  max_depth \n",
      "  -  ntrees \n",
      "Number of models: 60 \n",
      "Number of failed models: 0 \n",
      "\n",
      "Hyper-Parameter Search Summary: ordered by decreasing auc\n",
      "  max_depth ntrees        model_ids                auc\n",
      "1         2    100  my_grid_model_0 0.9943614130434784\n",
      "2         2   1900 my_grid_model_36 0.9941236413043478\n",
      "3         2    900 my_grid_model_16 0.9941236413043478\n",
      "4         2   1300 my_grid_model_24 0.9941236413043478\n",
      "5         2   1700 my_grid_model_32 0.9941236413043478\n",
      "\n",
      "---\n",
      "   max_depth ntrees        model_ids                auc\n",
      "55        11    300  my_grid_model_7 0.9920176630434783\n",
      "56        11   1300 my_grid_model_27 0.9920176630434783\n",
      "57        11    700 my_grid_model_15 0.9920176630434783\n",
      "58        11   1100 my_grid_model_23 0.9920176630434783\n",
      "59        11    100  my_grid_model_3 0.9920176630434783\n",
      "60        11    500 my_grid_model_11 0.9920176630434783\n"
     ]
    }
   ],
   "source": [
    "## sort the grid models by decreasing AUC\n",
    "sortedGrid <- h2o.getGrid(\"my_grid\", sort_by=\"auc\", decreasing = TRUE)    \n",
    "print(sortedGrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print out the top 10 models from the grid search. Below the AUC has increased to 0.96."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.9943614\n",
      "[1] 0.9941236\n",
      "[1] 0.9941236\n",
      "[1] 0.9941236\n",
      "[1] 0.9941236\n",
      "[1] 0.9941236\n",
      "[1] 0.9941236\n",
      "[1] 0.9941236\n",
      "[1] 0.9941236\n",
      "[1] 0.9941236\n"
     ]
    }
   ],
   "source": [
    "for (i in 1:10) {\n",
    "  gbm <- h2o.getModel(sortedGrid@model_ids[[i]])\n",
    "  print(h2o.auc(h2o.performance(gbm, valid = TRUE)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also understand the details of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details:\n",
      "==============\n",
      "\n",
      "H2OBinomialModel: gbm\n",
      "Model Key:  my_grid_model_0 \n",
      "Model Summary: \n",
      "  number_of_trees number_of_internal_trees model_size_in_bytes min_depth\n",
      "1             100                      100               11281         2\n",
      "  max_depth mean_depth min_leaves max_leaves mean_leaves\n",
      "1         2    2.00000          4          4     4.00000\n",
      "\n",
      "H2OBinomialMetrics: gbm\n",
      "** Reported on training data. **\n",
      "\n",
      "MSE:  0.01310199\n",
      "RMSE:  0.1144639\n",
      "LogLoss:  0.06946311\n",
      "Mean Per-Class Error:  0.01310559\n",
      "AUC:  0.9991718\n",
      "Gini:  0.9983437\n",
      "\n",
      "Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n",
      "       female male    Error    Rate\n",
      "female    147    3 0.020000  =3/150\n",
      "male        1  160 0.006211  =1/161\n",
      "Totals    148  163 0.012862  =4/311\n",
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "                        metric threshold    value idx\n",
      "1                       max f1  0.307003 0.987654  83\n",
      "2                       max f2  0.307003 0.991326  83\n",
      "3                 max f0point5  0.706392 0.993631  76\n",
      "4                 max accuracy  0.307003 0.987138  83\n",
      "5                max precision  0.978829 1.000000   0\n",
      "6                   max recall  0.119987 1.000000  91\n",
      "7              max specificity  0.978829 1.000000   0\n",
      "8             max absolute_mcc  0.307003 0.974313  83\n",
      "9   max min_per_class_accuracy  0.372230 0.980000  81\n",
      "10 max mean_per_class_accuracy  0.307003 0.986894  83\n",
      "\n",
      "Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n",
      "H2OBinomialMetrics: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE:  0.02866168\n",
      "RMSE:  0.1692976\n",
      "LogLoss:  0.1146398\n",
      "Mean Per-Class Error:  0.02798913\n",
      "AUC:  0.9943614\n",
      "Gini:  0.9887228\n",
      "\n",
      "Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n",
      "       female male    Error     Rate\n",
      "female    158    2 0.012500   =2/160\n",
      "male        8  176 0.043478   =8/184\n",
      "Totals    166  178 0.029070  =10/344\n",
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "                        metric threshold    value idx\n",
      "1                       max f1  0.752025 0.972376  84\n",
      "2                       max f2  0.430443 0.977444 101\n",
      "3                 max f0point5  0.752025 0.982143  84\n",
      "4                 max accuracy  0.752025 0.970930  84\n",
      "5                max precision  0.979391 1.000000   0\n",
      "6                   max recall  0.047903 1.000000 144\n",
      "7              max specificity  0.979391 1.000000   0\n",
      "8             max absolute_mcc  0.752025 0.942295  84\n",
      "9   max min_per_class_accuracy  0.675583 0.962500  90\n",
      "10 max mean_per_class_accuracy  0.752025 0.972011  84\n",
      "\n",
      "Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n",
      "\n",
      "\n",
      "Scoring History: \n",
      "             timestamp   duration number_of_trees training_rmse\n",
      "1  2018-07-19 14:36:17  0.008 sec               0       0.49969\n",
      "2  2018-07-19 14:36:17  0.088 sec              10       0.33067\n",
      "3  2018-07-19 14:36:17  0.129 sec              20       0.23972\n",
      "4  2018-07-19 14:36:17  0.179 sec              30       0.19043\n",
      "5  2018-07-19 14:36:17  0.240 sec              40       0.16376\n",
      "6  2018-07-19 14:36:17  0.287 sec              50       0.14734\n",
      "7  2018-07-19 14:36:17  0.332 sec              60       0.13624\n",
      "8  2018-07-19 14:36:17  0.373 sec              70       0.12927\n",
      "9  2018-07-19 14:36:17  0.423 sec              80       0.12310\n",
      "10 2018-07-19 14:36:17  0.480 sec              90       0.11867\n",
      "11 2018-07-19 14:36:17  0.618 sec             100       0.11446\n",
      "   training_logloss training_auc training_lift training_classification_error\n",
      "1           0.69252      0.50000       1.00000                       0.48232\n",
      "2           0.39936      0.99677       1.93168                       0.01929\n",
      "3           0.26506      0.99776       1.93168                       0.01929\n",
      "4           0.19327      0.99776       1.93168                       0.01929\n",
      "5           0.15151      0.99810       1.93168                       0.01608\n",
      "6           0.12462      0.99859       1.93168                       0.01608\n",
      "7           0.10563      0.99876       1.93168                       0.01608\n",
      "8           0.09289      0.99884       1.93168                       0.01608\n",
      "9           0.08251      0.99884       1.93168                       0.01608\n",
      "10          0.07548      0.99896       1.93168                       0.01608\n",
      "11          0.06946      0.99917       1.93168                       0.01286\n",
      "   validation_rmse validation_logloss validation_auc validation_lift\n",
      "1          0.49908            0.69130        0.50000         1.00000\n",
      "2          0.34217            0.41529        0.99334         1.86957\n",
      "3          0.25945            0.28688        0.99457         1.86957\n",
      "4          0.21858            0.22014        0.99434         1.86957\n",
      "5          0.19660            0.18091        0.99416         1.86957\n",
      "6          0.18464            0.15688        0.99394         1.86957\n",
      "7          0.17755            0.14056        0.99395         1.86957\n",
      "8          0.17340            0.12981        0.99416         1.86957\n",
      "9          0.17132            0.12266        0.99419         1.86957\n",
      "10         0.16965            0.11771        0.99426         1.86957\n",
      "11         0.16930            0.11464        0.99436         1.86957\n",
      "   validation_classification_error\n",
      "1                          0.46512\n",
      "2                          0.04651\n",
      "3                          0.03779\n",
      "4                          0.04070\n",
      "5                          0.03779\n",
      "6                          0.03198\n",
      "7                          0.03198\n",
      "8                          0.03198\n",
      "9                          0.02907\n",
      "10                         0.02907\n",
      "11                         0.02907\n",
      "\n",
      "Variable Importances: (Extract with `h2o.varimp`) \n",
      "=================================================\n",
      "\n",
      "Variable Importances: \n",
      "   variable relative_importance scaled_importance percentage\n",
      "1   meanfun          550.765747          1.000000   0.659380\n",
      "2       IQR          178.118576          0.323402   0.213245\n",
      "3       Q25           92.350830          0.167677   0.110563\n",
      "4       sfm            2.349819          0.004266   0.002813\n",
      "5      mode            2.227077          0.004044   0.002666\n",
      "6        sd            1.860992          0.003379   0.002228\n",
      "7    sp.ent            1.838467          0.003338   0.002201\n",
      "8    maxfun            1.808250          0.003283   0.002165\n",
      "9    minfun            0.940000          0.001707   0.001125\n",
      "10   mindom            0.849429          0.001542   0.001017\n",
      "11     skew            0.590007          0.001071   0.000706\n",
      "12  modindx            0.353022          0.000641   0.000423\n",
      "13 centroid            0.330093          0.000599   0.000395\n",
      "14      Q75            0.272143          0.000494   0.000326\n",
      "15  meandom            0.208831          0.000379   0.000250\n",
      "16   maxdom            0.178124          0.000323   0.000213\n",
      "17     kurt            0.121798          0.000221   0.000146\n",
      "18  dfrange            0.114439          0.000208   0.000137\n",
      "19 meanfreq            0.000000          0.000000   0.000000\n",
      "20   median            0.000000          0.000000   0.000000\n"
     ]
    }
   ],
   "source": [
    "best_model <- h2o.getModel(sortedGrid@model_ids[[1]])\n",
    "summary(best_model)\n",
    "\n",
    "scoring_history <- as.data.frame(best_model@model$scoring_history)\n",
    "#plot(scoring_history$number_of_trees, scoring_history$training_MSE, type=\"p\") #training mse\n",
    "#points(scoring_history$number_of_trees, scoring_history$validation_MSE, type=\"l\") #validation mse\n",
    "\n",
    "## get the actual number of trees\n",
    "ntrees <- best_model@model$model_summary$number_of_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objective 3: Plotting ROC, Precision-recall\n",
    "\n",
    "* Use H2o metric functions available [here](https://rdrr.io/cran/h2o/man/h2o.metric.html).\n",
    "\n",
    "### Learning Objective 4: Variable importance & Partial dependence plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# All done. Shut down H2O.\n",
    "h2o.shutdown(prompt=FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
